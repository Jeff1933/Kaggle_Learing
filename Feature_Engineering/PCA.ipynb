{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用于特征工程的 PCA¶\n",
    "# 有两种方法可以将 PCA 用于特征工程。\n",
    "\n",
    "# 第一种方法是将其用作描述性技术。\n",
    "# 由于分量会告诉您变异，因此您可以计算分量的 MI 分数，并查看哪种变异最能预测您的目标。\n",
    "# 这可以为您提供创建各种特征的想法 - 例如，如果“大小”很重要，则为“高度”和“直径”的乘积，如果形状很重要，则为“高度”和“直径”的比率。\n",
    "# 您甚至可以尝试在一个或多个高分组件上进行聚类。\n",
    "\n",
    "# 第二种方法是将组件本身用作特征。\n",
    "# 由于组件直接公开数据的变分结构，因此它们通常比原始特征提供更多信息。\n",
    "# 以下是一些用例：\n",
    "# 降维：当您的特征是高度冗余的（特别是多共线性）时，PCA 会将冗余划分为一个或多个接近零的方差分量，然后您可以删除这些分量，因为它们包含的信息很少或没有信息。\n",
    "# 异常检测：从原始特征中不明显的异常变异通常会出现在低方差分量中。这些组件在异常或异常值检测任务中可能具有很高的信息量。\n",
    "# 降噪：传感器读数的集合通常会共享一些常见的背景噪声。PCA有时可以将（信息性）信号收集到较少数量的特征中，同时不考虑噪声，从而提高信噪比。\n",
    "# 去相关：一些 ML 算法在处理高度相关的特征时遇到困难。PCA 将相关特征转换为不相关的组件，这可能更易于您的算法使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA最佳实践\n",
    "# 应用 PCA 时需要牢记以下几点：\n",
    "# PCA 仅适用于数值特征，例如连续数量或计数。\n",
    "# PCA对规模敏感。在应用 PCA 之前，最好先对数据进行标准化，除非您知道自己有充分的理由不这样做。\n",
    "# 考虑删除或约束异常值，因为它们可能会对结果产生不当影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "plt.rc(\"figure\", autolayout=True)\n",
    "plt.rc(\n",
    "    \"axes\",\n",
    "    labelweight=\"bold\",\n",
    "    labelsize=\"large\",\n",
    "    titleweight=\"bold\",\n",
    "    titlesize=14,\n",
    "    titlepad=10,\n",
    ")\n",
    "\n",
    "\n",
    "def plot_variance(pca, width=8, dpi=100):\n",
    "    # Create figure\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    n = pca.n_components_\n",
    "    grid = np.arange(1, n + 1)\n",
    "    # Explained variance\n",
    "    evr = pca.explained_variance_ratio_\n",
    "    axs[0].bar(grid, evr)\n",
    "    axs[0].set(\n",
    "        xlabel=\"Component\", title=\"% Explained Variance\", ylim=(0.0, 1.0)\n",
    "    )\n",
    "    # Cumulative Variance\n",
    "    cv = np.cumsum(evr)\n",
    "    axs[1].plot(np.r_[0, grid], np.r_[0, cv], \"o-\")\n",
    "    axs[1].set(\n",
    "        xlabel=\"Component\", title=\"% Cumulative Variance\", ylim=(0.0, 1.0)\n",
    "    )\n",
    "    # Set up figure\n",
    "    fig.set(figwidth=8, dpi=100)\n",
    "    return axs\n",
    "\n",
    "def make_mi_scores(X, y, discrete_features):\n",
    "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"../input/fe-course-data/autos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择几个ml值高的特征\n",
    "features = [\"highway_mpg\", \"engine_size\", \"horsepower\", \"curb_weight\"]\n",
    "\n",
    "X = df.copy()\n",
    "y = X.pop('price')\n",
    "X = X.loc[:, features]\n",
    "\n",
    "# Standardize\n",
    "X_scaled = (X - X.mean(axis=0)) / X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create principal components\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Convert to dataframe\n",
    "component_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\n",
    "X_pca = pd.DataFrame(X_pca, columns=component_names)\n",
    "\n",
    "X_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings = pd.DataFrame(\n",
    "    pca.components_.T,  # transpose the matrix of loadings\n",
    "    columns=component_names,  # so the columns are the principal components\n",
    "    index=X.columns,  # and the rows are the original features\n",
    ")\n",
    "loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at explained variance\n",
    "plot_variance(pca);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The third component shows a contrast between horsepower and curb_weight -- sports cars vs. wagons, it seems.\n",
    "# Show dataframe sorted by PC3\n",
    "idx = X_pca[\"PC3\"].sort_values(ascending=False).index\n",
    "cols = [\"make\", \"body_style\", \"horsepower\", \"curb_weight\"]\n",
    "df.loc[idx, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sports_or_wagon\"] = X.curb_weight / X.horsepower\n",
    "sns.regplot(x=\"sports_or_wagon\", y='price', data=df, order=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Set Matplotlib defaults\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "plt.rc(\"figure\", autolayout=True)\n",
    "plt.rc(\n",
    "    \"axes\",\n",
    "    labelweight=\"bold\",\n",
    "    labelsize=\"large\",\n",
    "    titleweight=\"bold\",\n",
    "    titlesize=14,\n",
    "    titlepad=10,\n",
    ")\n",
    "\n",
    "\n",
    "def apply_pca(X, standardize=True):\n",
    "    # Standardize\n",
    "    if standardize:\n",
    "        X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "    # Create principal components\n",
    "    pca = PCA()\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    # Convert to dataframe\n",
    "    component_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\n",
    "    X_pca = pd.DataFrame(X_pca, columns=component_names)\n",
    "    # Create loadings\n",
    "    loadings = pd.DataFrame(\n",
    "        pca.components_.T,  # transpose the matrix of loadings\n",
    "        columns=component_names,  # so the columns are the principal components\n",
    "        index=X.columns,  # and the rows are the original features\n",
    "    )\n",
    "    return pca, X_pca, loadings\n",
    "\n",
    "\n",
    "def plot_variance(pca, width=8, dpi=100):\n",
    "    # Create figure\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    n = pca.n_components_\n",
    "    grid = np.arange(1, n + 1)\n",
    "    # Explained variance\n",
    "    evr = pca.explained_variance_ratio_\n",
    "    axs[0].bar(grid, evr)\n",
    "    axs[0].set(\n",
    "        xlabel=\"Component\", title=\"% Explained Variance\", ylim=(0.0, 1.0)\n",
    "    )\n",
    "    # Cumulative Variance\n",
    "    cv = np.cumsum(evr)\n",
    "    axs[1].plot(np.r_[0, grid], np.r_[0, cv], \"o-\")\n",
    "    axs[1].set(\n",
    "        xlabel=\"Component\", title=\"% Cumulative Variance\", ylim=(0.0, 1.0)\n",
    "    )\n",
    "    # Set up figure\n",
    "    fig.set(figwidth=8, dpi=100)\n",
    "    return axs\n",
    "\n",
    "\n",
    "def make_mi_scores(X, y):\n",
    "    X = X.copy()\n",
    "    for colname in X.select_dtypes([\"object\", \"category\"]):\n",
    "        X[colname], _ = X[colname].factorize()\n",
    "    # All discrete features should now have integer dtypes\n",
    "    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n",
    "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "\n",
    "def score_dataset(X, y, model=XGBRegressor()):\n",
    "    # Label encoding for categoricals\n",
    "    for colname in X.select_dtypes([\"category\", \"object\"]):\n",
    "        X[colname], _ = X[colname].factorize()\n",
    "    # Metric for Housing competition is RMSLE (Root Mean Squared Log Error)\n",
    "    score = cross_val_score(\n",
    "        model, X, y, cv=5, scoring=\"neg_mean_squared_log_error\",\n",
    "    )\n",
    "    score = -1 * score.mean()\n",
    "    score = np.sqrt(score)\n",
    "    return score\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"../input/fe-course-data/ames.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's choose a few features that are highly correlated with our target, SalePrice.\n",
    "features = [\n",
    "    \"GarageArea\",\n",
    "    \"YearRemodAdd\",\n",
    "    \"TotalBsmtSF\",\n",
    "    \"GrLivArea\",\n",
    "]\n",
    "\n",
    "print(\"Correlation with SalePrice:\\n\")\n",
    "print(df[features].corrwith(df.SalePrice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.copy()\n",
    "y = X.pop(\"SalePrice\")\n",
    "X = X.loc[:, features]\n",
    "\n",
    "# `apply_pca`, defined above, reproduces the code from the tutorial\n",
    "pca, X_pca, loadings = apply_pca(X)\n",
    "print(loadings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新增特征来提高模型性能\n",
    "# Solution 1: Inspired by loadings\n",
    "X = df.copy()\n",
    "y = X.pop(\"SalePrice\")\n",
    "\n",
    "X[\"Feature1\"] = X.GrLivArea + X.TotalBsmtSF\n",
    "X[\"Feature2\"] = X.YearRemodAdd * X.TotalBsmtSF\n",
    "\n",
    "score = score_dataset(X, y)\n",
    "print(f\"Your score: {score:.5f} RMSLE\")\n",
    "\n",
    "\n",
    "# Solution 2: Uses components\n",
    "X = df.copy()\n",
    "y = X.pop(\"SalePrice\")\n",
    "\n",
    "X = X.join(X_pca)\n",
    "score = score_dataset(X, y)\n",
    "print(f\"Your score: {score:.5f} RMSLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier Detection\n",
    "sns.catplot(\n",
    "    y=\"value\",\n",
    "    col=\"variable\",\n",
    "    data=X_pca.melt(),\n",
    "    kind='boxen',\n",
    "    sharey=False,\n",
    "    col_wrap=2,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can change PC1 to PC2, PC3, or PC4\n",
    "component = \"PC1\"\n",
    "\n",
    "idx = X_pca[component].sort_values(ascending=False).index\n",
    "df.loc[idx, [\"SalePrice\", \"Neighborhood\", \"SaleCondition\"] + features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 您是否注意到极值中的任何模式？异常值是否似乎来自数据的某个特殊子集？\n",
    "# 请注意，在爱德华兹附近有几套住宅被列为部分销售，非常突出。\n",
    "# 部分出售是指当一个财产有多个所有者并且其中一个或多个出售其对财产的“部分”所有权时发生的情况。\n",
    "\n",
    "#这类销售通常发生在家庭财产的结算或企业解散期间，并且不会公开宣传。\n",
    "# 如果你试图预测房子在公开市场上的价值，你可能有理由从你的数据集中删除这样的销售——它们确实是异常值。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
